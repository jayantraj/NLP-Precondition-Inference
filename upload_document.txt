Complete this document and upload along with your prediction results and your code.

### Method Name ###
Use a phrasal name to describe your method, e.g. training a BiLSTM cross-encoder from scratch, fine-tuning RoBERTa-large-MNLI, etc.

Fine-tuning RoBERTa-Base

### Sentence pair encoder ###
Use up to 5 sentences to describe your encoder for the sentence pairs. Need to mention the following:
- Is it a bi-encoder or cross-encoder?
- What type of encoder (LSTM, Transformer, etc.)
- Is it based on a pre-trained model (BERT-large? RoBERTa-large-SNLI? BART-large-MNLI?) or completely trained from scratch by yourself (then how do you chracterize the words and aggregate them into sentence representations)?

I have used Transformer& bi-encoder. My pre-trained model was RoBERTa-large.

### Training & Development ###
Up to 5 sentences: how did you evaluate your solution using the dev set before submitting to the leaderboard? What are some key hyperparameter values (e.g., optimizer, learning rate, batch size, etc.)? Did you fine-tune your model or just conducted zero-shot transfer from a pre-trained model? If fine-tuning, what portion of data did you use and how did you terminate the training (using a fixed #epochs, early stopping based on dev set performance)?

I evaluated my solution using the accuracy metric and also I checked whether the balance between the two classes was reflected in my results. I also used early stopping to prevent my model from overfitting. Optimizer: Adam, Learning Rate: 1e^-5, batch size = 32. I used the whole validation set for fine-tuning and stopped my training when the validation accuracy didn't increase for more than 3 epochs.

### Other methods ###
Did you try other methods than the submitted one?

I tried BERT-Base, the Pre-trained ALBERT model. I also tried to use the SNLI dataset for generating my predictions. Since the SNLI dataset had three classes (entail, contradict, neutral), I modified the dataset by combining contradict and neutral to the same class. But training the model took a long time, hence didn't continue with it.

### Packages ###
List the key python packages you have used in this assignment.

numpy 
pandas
tensorflow 
RobertaTokenizer from transformers
keras.callbacks
sklearn
